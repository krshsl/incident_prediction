{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is the first step toward creating the input for our project\n",
    "\n",
    "\n",
    "__Main Steps__\n",
    "\n",
    "* _Libraries_: Run requirements.txt to install the required libraries. It is recommended to use a venv.\n",
    "\n",
    "* _Load traffic event data_: Traffic events taken from https://smoosavi.org/datasets/lstw - Please run the get_files.sh script to download the required files\n",
    "\n",
    "* _Load Sunlight data_: Sunlight data was downloaded from https://sunrise-sunset.org/, and it is downloaded/stored in this code\n",
    "\n",
    "* _Load Weather event data_: Weather events are downloaded dynamically from copernicus(default)/oikolab for specific lat and long. The copernicus data is obtained at 5km grid level, while oikolab can only be obtained at 25km level unless the user has a paid subscription.\n",
    "\n",
    "* _Construct Feature Vectors for pairs of City-Geohash_: This would be an initial feature csv that only contains time, traffic, and weather information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:30.491269Z",
     "iopub.status.busy": "2025-04-26T23:11:30.491039Z",
     "iopub.status.idle": "2025-04-26T23:11:31.310557Z",
     "shell.execute_reply": "2025-04-26T23:11:31.309855Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count, Lock\n",
    "from urllib.request import Request, urlopen\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import requests\n",
    "import cdsapi\n",
    "import pprint\n",
    "import pytz\n",
    "import math\n",
    "import csv\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:31.314242Z",
     "iopub.status.busy": "2025-04-26T23:11:31.313750Z",
     "iopub.status.idle": "2025-04-26T23:11:31.326242Z",
     "shell.execute_reply": "2025-04-26T23:11:31.325693Z"
    }
   },
   "outputs": [],
   "source": [
    "from common import cities, city_keys, years, months\n",
    "\n",
    "# defaulting to 1st date for both\n",
    "start_date = pd.to_datetime(f\"{years[0]}-{months[0]}-01 00:00:00\")\n",
    "end_date = pd.to_datetime(f\"{years[-1]}-{months[-1]}-01 00:00:00\")\n",
    "if start_date == end_date:\n",
    "    end_date = pd.to_datetime(f\"{years[-1]}-{months[-1]}-02 00:00:00\")\n",
    "    month_ranges = [f\"{years[0]}-{months[0]}-01/{years[-1]}-{months[-1]}-02\"]\n",
    "else:\n",
    "    month_ranges = [ # costly requests can take longer, might as well get one month at a time...\n",
    "        (f'{d.strftime('%Y-%m-01')}/{(d + pd.offsets.MonthBegin(1)).strftime('%Y-%m-01')}')\n",
    "        for d in pd.date_range(start=start_date, end=end_date, freq='MS') if d < end_date\n",
    "    ]\n",
    "\n",
    "class W_MODEL_API:\n",
    "    OIKO = \"OIKO\"\n",
    "    ECMFW = \"ECMFW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:31.328559Z",
     "iopub.status.busy": "2025-04-26T23:11:31.328028Z",
     "iopub.status.idle": "2025-04-26T23:11:31.334318Z",
     "shell.execute_reply": "2025-04-26T23:11:31.333746Z"
    }
   },
   "outputs": [],
   "source": [
    "month_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:31.377001Z",
     "iopub.status.busy": "2025-04-26T23:11:31.376752Z",
     "iopub.status.idle": "2025-04-26T23:11:31.383940Z",
     "shell.execute_reply": "2025-04-26T23:11:31.383080Z"
    }
   },
   "outputs": [],
   "source": [
    "dirs = ['data', 'data/traffic', 'data/weather', 'data/input', 'data/sample_daylight']\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "load_dotenv(dotenv_path=os.path.abspath('./prod.env'))\n",
    "api_key = os.environ['OIKOLAB_API']\n",
    "url = 'https://api.oikolab.com/weather' # this is paid, use at your own discretion\n",
    "weather_model = W_MODEL_API.OIKO\n",
    "\n",
    "max_cores = len(city_keys) if len(city_keys) < cpu_count() else cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:31.386880Z",
     "iopub.status.busy": "2025-04-26T23:11:31.386113Z",
     "iopub.status.idle": "2025-04-26T23:11:31.866095Z",
     "shell.execute_reply": "2025-04-26T23:11:31.865027Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(os.environ['HOME'],'.cdsapirc'), 'w') as file:\n",
    "    file.write(f'url: https://cds.climate.copernicus.eu/api\\n')\n",
    "    file.write(f'key: {os.environ['CDS_API']}\\n')\n",
    "\n",
    "\n",
    "weather_model = W_MODEL_API.ECMFW\n",
    "\n",
    "cdsClient = cdsapi.Client()\n",
    "\n",
    "# ecmwf_paramters = '141.128/164.128/165.128/166.128/167.128/228089.128/228090.128/228219.128'\n",
    "# [ # https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#heading-Parameterlistings\n",
    "#     \"snow_depth\", #141 sd\n",
    "#     \"total_cloud_cover\", #164 tcc\n",
    "#     \"10m_u_component_of_wind\", #165 u10\n",
    "#     \"10m_v_component_of_wind\", #166 v10\n",
    "#     \"2m_temperature\", # 167 t2m\n",
    "#     \"total_column_rain_water\", #228089 tcrw\n",
    "#     \"total_column_snow_water\", #228089 tcsw\n",
    "#     \"large_scale_rain_rate\", #228219 lsrr\n",
    "#     \"large_scale_snowfall_rate_water_equivalent\" #228221 lssfr\n",
    "# ]\n",
    "\n",
    "ecmwf_variables = [\n",
    "    [\n",
    "        '2m_temperature',\n",
    "        '10m_u_component_of_wind',\n",
    "        '10m_v_component_of_wind',\n",
    "        'instantaneous_10m_wind_gust',\n",
    "        'snow_depth', \n",
    "        'total_cloud_cover'\n",
    "    ],\n",
    "    [\n",
    "        'total_precipitation'\n",
    "    ],\n",
    "    # [ # ignoring snowfall in favor of snow depth and precip?\n",
    "    #     'snowfall'\n",
    "    # ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sunrise Sunset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:31.869121Z",
     "iopub.status.busy": "2025-04-26T23:11:31.868630Z",
     "iopub.status.idle": "2025-04-26T23:11:32.612555Z",
     "shell.execute_reply": "2025-04-26T23:11:32.611394Z"
    }
   },
   "outputs": [],
   "source": [
    "for (city, city_vals) in cities.items():\n",
    "    file = open(f\"data/sample_daylight/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv.csv\", \"w\")\n",
    "    wr_csv = csv.writer(file)\n",
    "    is_header = False\n",
    "    s_month = 1\n",
    "    for year in years:\n",
    "        s_end = months[-1] if (len(years) > 1 and years[-1] == year) or (len(years)==1) else 12\n",
    "        s_start = months[0] if (s_month==1) else 1\n",
    "        s_month = 0\n",
    "        for month in range(s_start, s_end+1, 1):\n",
    "            req = Request(\n",
    "                url = f'https://sunrise-sunset.org/us/{city_vals['sunrise']}/{year}/{month}', \n",
    "                headers={'User-Agent': 'Mozilla/5.0'} # weirdly enough we get auth errors w/o this??\n",
    "            )\n",
    "            html = urlopen(req).read()\n",
    "            soup =  BeautifulSoup(html)\n",
    "            for span in soup.find_all(\"span\", {'class':'tooltip'}): \n",
    "                span.decompose()\n",
    "            \n",
    "            table = soup.select_one(\"table#month\")\n",
    "\n",
    "            if not is_header:\n",
    "                th_all = table.select(\"tr.headers th\")\n",
    "                headers = [th.text for th in th_all]\n",
    "                headers.append('Cities')\n",
    "                wr_csv.writerow(headers)\n",
    "                is_header = True\n",
    "            \n",
    "            tr_all = table.select(\"tr.day\")\n",
    "            day = 1\n",
    "            for tr in tr_all:\n",
    "                td_all = [td.text for td in tr.select(\"th,td\")]\n",
    "                td_all[0] = f'{year}-{month}-{day}'\n",
    "                day += 1\n",
    "                td_all.append(city)\n",
    "                wr_csv.writerow(td_all)\n",
    "\n",
    "    print(file.name)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the traffic events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:11:32.615425Z",
     "iopub.status.busy": "2025-04-26T23:11:32.615176Z",
     "iopub.status.idle": "2025-04-26T23:13:13.338679Z",
     "shell.execute_reply": "2025-04-26T23:13:13.336453Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events = pd.read_csv('TrafficEvents_Aug16_Dec20_Publish.csv') # This is the latest version of LSTW dataset\n",
    "# get the data from https://smoosavi.org/datasets/lstw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:13.343264Z",
     "iopub.status.busy": "2025-04-26T23:13:13.342718Z",
     "iopub.status.idle": "2025-04-26T23:13:47.862726Z",
     "shell.execute_reply": "2025-04-26T23:13:47.861572Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events['StartTime(UTC)'] = pd.to_datetime(t_events['StartTime(UTC)'], utc=True)\n",
    "t_events['EndTime(UTC)'] = pd.to_datetime(t_events['EndTime(UTC)'], utc=True)\n",
    "t_events['StartTime'] = t_events['StartTime(UTC)']\n",
    "t_events['EndTime'] = t_events['EndTime(UTC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:47.866378Z",
     "iopub.status.busy": "2025-04-26T23:13:47.866166Z",
     "iopub.status.idle": "2025-04-26T23:13:52.201540Z",
     "shell.execute_reply": "2025-04-26T23:13:52.200746Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events = t_events[(t_events['StartTime(UTC)'] >= start_date.tz_localize('UTC')) & (t_events['EndTime(UTC)'] < end_date.tz_localize('UTC'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:52.205645Z",
     "iopub.status.busy": "2025-04-26T23:13:52.205479Z",
     "iopub.status.idle": "2025-04-26T23:13:52.244096Z",
     "shell.execute_reply": "2025-04-26T23:13:52.243578Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:52.247357Z",
     "iopub.status.busy": "2025-04-26T23:13:52.247190Z",
     "iopub.status.idle": "2025-04-26T23:13:52.253335Z",
     "shell.execute_reply": "2025-04-26T23:13:52.252688Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subset(city_vals):\n",
    "    tzone = pytz.timezone(city_vals['timezone'])\n",
    "    crds = city_vals['coordinates']\n",
    "    \n",
    "    subset_all = t_events[(t_events['LocationLat']>crds[0]) & (t_events['LocationLat']<crds[2]) & (t_events['LocationLng']>crds[1]) & \n",
    "                    (t_events['LocationLng']<crds[3])]\n",
    "    subset_all['StartTime'].dt.tz_convert(tzone)\n",
    "    subset_all['EndTime'].dt.tz_convert(tzone)\n",
    "    subset_all = subset_all.copy()\n",
    "    subset_all['Type'] = subset_all['Type'].str.replace('-', '')\n",
    "    \n",
    "    subset_accidents = subset_all[(subset_all['Type']=='Accident')]\n",
    "\n",
    "    return subset_all, subset_accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:52.255676Z",
     "iopub.status.busy": "2025-04-26T23:13:52.255446Z",
     "iopub.status.idle": "2025-04-26T23:13:52.260668Z",
     "shell.execute_reply": "2025-04-26T23:13:52.260212Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_traffic(city):\n",
    "    city_vals = cities[city]\n",
    "    subset_all, subset_accidents = get_subset(city_vals)\n",
    "    subset_all.to_csv(f'data/traffic/TD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv', index=False)\n",
    "    if len(subset_all):\n",
    "        print(f'For {city} we have {len(subset_all)} incidents, with {len(subset_accidents)} accidents! ratio {len(subset_accidents)*1.0/len(subset_all):.2f}')\n",
    "    return subset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:52.262809Z",
     "iopub.status.busy": "2025-04-26T23:13:52.262655Z",
     "iopub.status.idle": "2025-04-26T23:13:53.286526Z",
     "shell.execute_reply": "2025-04-26T23:13:53.285845Z"
    }
   },
   "outputs": [],
   "source": [
    "tt_events = {}\n",
    "with Pool(max_cores) as p:\n",
    "    for i, event in enumerate(p.map(clean_traffic, city_keys)):\n",
    "        tt_events[city_keys[i]] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.289547Z",
     "iopub.status.busy": "2025-04-26T23:13:53.289296Z",
     "iopub.status.idle": "2025-04-26T23:13:53.311386Z",
     "shell.execute_reply": "2025-04-26T23:13:53.310826Z"
    }
   },
   "outputs": [],
   "source": [
    "for city in city_keys:\n",
    "    pprint.pprint(tt_events[city].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.313554Z",
     "iopub.status.busy": "2025-04-26T23:13:53.313287Z",
     "iopub.status.idle": "2025-04-26T23:13:53.316911Z",
     "shell.execute_reply": "2025-04-26T23:13:53.316263Z"
    }
   },
   "outputs": [],
   "source": [
    "del t_events # major abuser of memory removed??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.319501Z",
     "iopub.status.busy": "2025-04-26T23:13:53.319003Z",
     "iopub.status.idle": "2025-04-26T23:13:53.330316Z",
     "shell.execute_reply": "2025-04-26T23:13:53.329622Z"
    }
   },
   "outputs": [],
   "source": [
    "class OIKO:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "\n",
    "    def get_weather_data(self, sdate, edate):\n",
    "        lat = []\n",
    "        long = []\n",
    "        city_vals = cities[self.city]\n",
    "\n",
    "        for (la, lo) in city_vals['weather']:\n",
    "            lat.append(la)\n",
    "            long.append(lo)\n",
    "        \n",
    "        response = requests.get(url,\n",
    "            params={'param': ['temperature', '10m_wind_gust', 'relative_humidity', 'wind_speed', 'wind_direction', 'total_cloud_cover', 'total_precipitation', 'snowfall'],\n",
    "                    'lat': lat,\n",
    "                    'lon': long,\n",
    "                    'start': sdate,\n",
    "                    'end': edate,\n",
    "                    'format': 'csv'},\n",
    "                    headers={'api-key': api_key}\n",
    "            )\n",
    "        \n",
    "        output = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+', delete=True) as tmp:\n",
    "            tmp.write(response.text)\n",
    "            output = pd.read_csv(tmp.name)\n",
    "            \n",
    "        \n",
    "        return output\n",
    "\n",
    "    def sample_weather(self):\n",
    "        tzone = pytz.timezone(cities[self.city]['timezone'])\n",
    "        traffic = pd.read_csv(f'data/traffic/TD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "        if (len(traffic) == 0):\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # since weather is obtained based on utc, we use utc. shouldn't matter if the local time is different\n",
    "        traffic['StartTime(UTC)'] = pd.to_datetime(traffic['StartTime(UTC)'])\n",
    "        traffic = traffic.sort_values('StartTime(UTC)').set_index('StartTime(UTC)')\n",
    "        f_out = self.get_weather_data(traffic.index.min().date(), traffic.index.max().date())\n",
    "        f_out.columns = [col.partition(' ')[0] for col in f_out.columns] # ignore the suffix in col names\n",
    "        f_out['datetime'] = pd.to_datetime(f_out['datetime'], utc=True)\n",
    "        f_out['datetime(UTC)'] = f_out['datetime']\n",
    "        f_out['datetime'].dt.tz_convert(tzone)\n",
    "        f_out[['LocationLat', 'LocationLng']] = f_out['coordinates'].apply(lambda x: pd.Series(ast.literal_eval(x)) if isinstance(x, str) else pd.Series(x) if isinstance(x, (list, tuple)) and len(x) == 2 else pd.Series([None, None]))\n",
    "        f_out.drop(columns=['coordinates'], inplace=True)\n",
    "        f_out.to_csv(f'data/weather/WD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "        return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.332598Z",
     "iopub.status.busy": "2025-04-26T23:13:53.332242Z",
     "iopub.status.idle": "2025-04-26T23:13:53.340218Z",
     "shell.execute_reply": "2025-04-26T23:13:53.339752Z"
    }
   },
   "outputs": [],
   "source": [
    "class ECMWF:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "\n",
    "    def get_weather_data(self):\n",
    "        coords = cities[self.city]['coordinates']\n",
    "        datasets = []\n",
    "        output_nc = []\n",
    "        output_dirs = []\n",
    "        index = 0\n",
    "        for date in month_ranges:\n",
    "            curr_var_set = []\n",
    "            for vars in ecmwf_variables:\n",
    "                output_dirs.append(tempfile.TemporaryDirectory(delete=True))\n",
    "                output_nc.append(os.path.join(output_dirs[index].name, f'era5_data{index}.nc'))\n",
    "                cdsClient.retrieve(\n",
    "                    'reanalysis-era5-single-levels',\n",
    "                    {\n",
    "                        'product_type': 'reanalysis',\n",
    "                        'format': 'netcdf',\n",
    "                        'variable': vars,\n",
    "                        'date': date,\n",
    "                        'time': '00/to/23/by/1',\n",
    "                        'area': coords,\n",
    "                        'grid': [0.05, 0.05],\n",
    "                        'data_format': 'netcdf'\n",
    "                    },\n",
    "                    output_nc[index]\n",
    "                )\n",
    "                curr_var_set.append(xr.open_dataset(output_nc[index], engine='netcdf4').load())\n",
    "                index += 1\n",
    "            \n",
    "            \n",
    "            datasets.append(xr.merge(curr_var_set))\n",
    "            del curr_var_set\n",
    "        \n",
    "        df = (xr.merge(datasets)).to_dataframe().reset_index()\n",
    "        for i in range(len(ecmwf_variables)*len(month_ranges)):\n",
    "            if i < len(output_nc):\n",
    "                os.remove(output_nc[i])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        del datasets\n",
    "        return df\n",
    "\n",
    "    def sample_weather(self):\n",
    "        tzone = pytz.timezone(cities[self.city]['timezone'])\n",
    "        f_out = self.get_weather_data()\n",
    "        f_out['time'] = pd.to_datetime(f_out['valid_time'], utc=True)\n",
    "        f_out['time(UTC)'] = f_out['time']\n",
    "        f_out['time'].dt.tz_convert(tzone)\n",
    "        f_out.to_csv(f'data/weather/WD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv', index=False)\n",
    "        return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.342262Z",
     "iopub.status.busy": "2025-04-26T23:13:53.341793Z",
     "iopub.status.idle": "2025-04-26T23:13:53.345103Z",
     "shell.execute_reply": "2025-04-26T23:13:53.344644Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weather_api(city):\n",
    "    if weather_model == W_MODEL_API.OIKO:\n",
    "        # for unit of measurements please refer https://docs.oikolab.com/parameters/\n",
    "        return OIKO(city)\n",
    "    else:\n",
    "        # rate limited to one request per user, so might as well perform single threaded operation\n",
    "        # for unit of measurements please refer https://cds.climate.copernicus.eu/datasets\n",
    "        return ECMWF(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.346799Z",
     "iopub.status.busy": "2025-04-26T23:13:53.346580Z",
     "iopub.status.idle": "2025-04-26T23:13:53.349601Z",
     "shell.execute_reply": "2025-04-26T23:13:53.349111Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_weather(city):\n",
    "    return get_weather_api(city).sample_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:13:53.351265Z",
     "iopub.status.busy": "2025-04-26T23:13:53.351054Z",
     "iopub.status.idle": "2025-04-26T23:14:45.839071Z",
     "shell.execute_reply": "2025-04-26T23:14:45.838162Z"
    }
   },
   "outputs": [],
   "source": [
    "wt_events = {}\n",
    "with Pool(max_cores) as p:\n",
    "    for i, event in enumerate(p.map(sample_weather, city_keys)):\n",
    "        wt_events[city_keys[i]] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.842081Z",
     "iopub.status.busy": "2025-04-26T23:14:45.841771Z",
     "iopub.status.idle": "2025-04-26T23:14:45.861046Z",
     "shell.execute_reply": "2025-04-26T23:14:45.860445Z"
    }
   },
   "outputs": [],
   "source": [
    "for city in city_keys:\n",
    "    print(city, wt_events[city].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate final input csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.863511Z",
     "iopub.status.busy": "2025-04-26T23:14:45.863090Z",
     "iopub.status.idle": "2025-04-26T23:14:45.872838Z",
     "shell.execute_reply": "2025-04-26T23:14:45.871776Z"
    }
   },
   "outputs": [],
   "source": [
    "ttype_dict = {\n",
    "    'Construction': 0, # let's ignore insig events atm\n",
    "    'Event': 1,\n",
    "    'FlowIncident': 2,\n",
    "    'LaneBlocked': 3,\n",
    "    'BrokenVehicle': 4,\n",
    "    'Congestion': 5,\n",
    "    'Accident': 6\n",
    "}\n",
    "\n",
    "class Traffic_Event:\n",
    "    Severity: int = 0\n",
    "    StartTime: datetime = None\n",
    "    EndTime: datetime = None\n",
    "    LocationLat: float = 0\n",
    "    LocationLng: float = 0\n",
    "    Type: int = -1\n",
    "    # Accident: int = 0\n",
    "    # BrokenVehicle: int  = 0\n",
    "    # Congestion: int  = 0\n",
    "    # Construction: int  = 0\n",
    "    # Event: int  = 0\n",
    "    # FlowIncident: int  = 0\n",
    "    # LaneBlocked: int  = 0\n",
    "\n",
    "    def __init__(self, trafficRow, weatherRow, daylightRow):\n",
    "        self.Type = ttype_dict[trafficRow['Type']]\n",
    "        if (self.Type < 2):\n",
    "            return\n",
    "        self.StartTime = trafficRow['StartTime']\n",
    "        self.EndTime = trafficRow['EndTime']\n",
    "        self.Sunrise = daylightRow['Twilight Start'].time()\n",
    "        self.Sunset = daylightRow['Twilight End'].time()\n",
    "        # self.Severity = trafficRow['Severity'] # we can't predict severity, so it's alright i guess??\n",
    "        if (weather_model == W_MODEL_API.OIKO):\n",
    "            self.Snowfall = weatherRow['snowfall']\n",
    "            self.Precipitation = weatherRow['total_precipitation']\n",
    "            self.CloudCover = weatherRow['total_cloud_cover']\n",
    "            self.WindDirection = weatherRow['wind_direction']\n",
    "            self.WindSpeed = weatherRow['wind_speed']\n",
    "            self.RelativeHumidity = weatherRow['relative_humidity']\n",
    "            self.WindGust = weatherRow['10m_wind_gust']\n",
    "            self.Temperature = weatherRow['temperature']\n",
    "\n",
    "            ### I urge you to modify our code to make these parts work. We are only using ECMWF, so you might have to manually fix the grid\n",
    "            self.LocationLat = trafficRow['LocationLat']\n",
    "            self.LocationLng = trafficRow['LocationLng']\n",
    "        else:\n",
    "            self.LocationLat = weatherRow['latitude'] # closest 5km grid lat\n",
    "            self.LocationLng = weatherRow['longitude'] # closest 5km grid lng\n",
    "            self.SnowDept = weatherRow['sd']\n",
    "            # if 'sf' in weatherRow:\n",
    "            #     self.SnowFall = weatherRow['sf']\n",
    "            self.CloudCover = weatherRow['tcc']\n",
    "            self.UWind = weatherRow['u10']\n",
    "            self.VWind = weatherRow['v10']\n",
    "            if 'i10fg' in weatherRow:\n",
    "                self.Gust = weatherRow['i10fg']\n",
    "            self.Temperature = weatherRow['t2m']\n",
    "            if 'tp' in weatherRow:\n",
    "                self.Precipitation = weatherRow['tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.876251Z",
     "iopub.status.busy": "2025-04-26T23:14:45.875823Z",
     "iopub.status.idle": "2025-04-26T23:14:45.880926Z",
     "shell.execute_reply": "2025-04-26T23:14:45.880184Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371000 * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.883255Z",
     "iopub.status.busy": "2025-04-26T23:14:45.882662Z",
     "iopub.status.idle": "2025-04-26T23:14:45.887028Z",
     "shell.execute_reply": "2025-04-26T23:14:45.886251Z"
    }
   },
   "outputs": [],
   "source": [
    "file_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.889510Z",
     "iopub.status.busy": "2025-04-26T23:14:45.888888Z",
     "iopub.status.idle": "2025-04-26T23:14:45.893055Z",
     "shell.execute_reply": "2025-04-26T23:14:45.892400Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_file(path, events: pd.DataFrame):\n",
    "    with file_lock:\n",
    "        if os.path.exists(path):\n",
    "            curr_events = pd.read_csv(path)\n",
    "            pd.concat([events, curr_events], ignore_index=True).to_csv(path, index=False)\n",
    "        else:\n",
    "            events.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:45.895273Z",
     "iopub.status.busy": "2025-04-26T23:14:45.894879Z",
     "iopub.status.idle": "2025-04-26T23:14:46.034937Z",
     "shell.execute_reply": "2025-04-26T23:14:46.034185Z"
    }
   },
   "outputs": [],
   "source": [
    "tt_events = {}\n",
    "wt_events = {}\n",
    "dl_events = {}\n",
    "for city in city_keys:\n",
    "    d_curr = pd.read_csv(f\"data/sample_daylight/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv.csv\")\n",
    "    d_curr['Twilight Start'] = pd.to_datetime(d_curr['Twilight Start'], format='%I:%M:%S %p')\n",
    "    d_curr['Twilight End'] = pd.to_datetime(d_curr['Twilight End'], format='%I:%M:%S %p')\n",
    "    d_curr['Day'] = pd.to_datetime(d_curr['Day'])\n",
    "    t_curr = pd.read_csv(f'data/traffic/TD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "    t_curr['StartTime(UTC)'] = pd.to_datetime(t_curr['StartTime(UTC)'], utc=True)\n",
    "    t_curr['EndTime(UTC)'] = pd.to_datetime(t_curr['EndTime(UTC)'], utc=True)\n",
    "    w_curr = pd.read_csv(f'data/weather/WD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "    w_curr['time(UTC)'] = pd.to_datetime(w_curr['time(UTC)'], utc=True)\n",
    "    tt_events[city] = t_curr\n",
    "    wt_events[city] = w_curr\n",
    "    dl_events[city] = d_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:46.038110Z",
     "iopub.status.busy": "2025-04-26T23:14:46.037817Z",
     "iopub.status.idle": "2025-04-26T23:14:46.045473Z",
     "shell.execute_reply": "2025-04-26T23:14:46.044832Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_input(args):\n",
    "    city = args[0]\n",
    "    t_curr = tt_events[city]\n",
    "    w_curr = wt_events[city]\n",
    "    d_curr = dl_events[city]\n",
    "    t_curr['StartTime(UTC)'] = t_curr['StartTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0, microsecond=0))\n",
    "    t_curr['EndTime(UTC)'] = t_curr['EndTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0, microsecond=0))\n",
    "    start_i = args[1]\n",
    "    end_i = args[2]\n",
    "    file = args[3]\n",
    "    \n",
    "    events = []\n",
    "    for index, row in t_curr.iterrows():\n",
    "        if index < start_i:\n",
    "            continue\n",
    "        elif index >= end_i:\n",
    "            break\n",
    "\n",
    "        d_match = d_curr[(d_curr['Day'].dt.date == row['StartTime(UTC)'].date())]\n",
    "        w_match = w_curr[(w_curr['time(UTC)'] == row['StartTime(UTC)'])].copy()\n",
    "        w_match['distance'] = haversine(w_match['latitude'], w_match['longitude'], row['LocationLat'], row['LocationLng'])\n",
    "        if w_match.empty or d_match.empty:\n",
    "            continue\n",
    "        \n",
    "        w_match = w_match[w_match['distance'].min() == w_match['distance']].iloc[0]\n",
    "        te = Traffic_Event(row, w_match, d_match.iloc[0])\n",
    "        if te.Type < 2:\n",
    "            continue\n",
    "        events.append(vars(te))\n",
    "    \n",
    "    write_file(file, pd.DataFrame(events))\n",
    "    del events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:46.047292Z",
     "iopub.status.busy": "2025-04-26T23:14:46.047078Z",
     "iopub.status.idle": "2025-04-26T23:14:55.714091Z",
     "shell.execute_reply": "2025-04-26T23:14:55.713236Z"
    }
   },
   "outputs": [],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    for city in city_keys:\n",
    "        events = []\n",
    "        if (len(t_curr) == 0 or len(w_curr) == 0):\n",
    "            continue\n",
    "\n",
    "        file = f'data/input/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv'\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "        per_cpu = len(tt_events[city])//cpu_count()\n",
    "        count = math.ceil(len(tt_events[city])/per_cpu)\n",
    "        args = [[city, per_cpu*i, per_cpu*(i+1), file] for i in range(count)]\n",
    "        print(city, count)\n",
    "        p.map(sample_input, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-26T23:14:55.717213Z",
     "iopub.status.busy": "2025-04-26T23:14:55.716864Z",
     "iopub.status.idle": "2025-04-26T23:14:55.720587Z",
     "shell.execute_reply": "2025-04-26T23:14:55.720128Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## helper terminal??\n",
    "# # !echo '--- reading traffic events...'\n",
    "# # !head -n 3 TrafficEvents_Aug16_Dec20_Publish.csv\n",
    "# # !echo '--- reading weather events...'\n",
    "# # !head -n 3 WeatherEvents_Aug16_Dec20_Publish.csv\n",
    "# # !echo '--- traffic event types'\n",
    "# # !tail -n +2 TrafficEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $2}' | sort | uniq\n",
    "# # !echo '--- weather event types'\n",
    "# # !tail -n +2 WeatherEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $2}' | sort | uniq\n",
    "# # !echo '--- weather event severity'\n",
    "# # !tail -n +2 WeatherEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $3}' | sort | uniq\n",
    "# # !tail -n+2 data/traffic/MQ_Austin*.csv | awk -F, '{print $9,$10}' | sort | uniq | wc -l\n",
    "# # !tail -n+2 data/traffic/MQ_Austin*.csv | wc -l\n",
    "\n",
    "\n",
    "# ## helper account details??\n",
    "# rr = requests.get('https://api.oikolab.com/account',\n",
    "#                  headers={'api-key': api_key}\n",
    "#                  )\n",
    "\n",
    "# rr.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
