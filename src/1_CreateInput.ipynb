{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook is the first step toward creating the input for our project\n",
    "\n",
    "\n",
    "__Main Steps__\n",
    "\n",
    "* _Libraries_: Run requirements.txt to install the required libraries. It is recommended to use a venv.\n",
    "\n",
    "* _Load traffic event data_: Traffic events taken from https://smoosavi.org/datasets/lstw - Please run the get_files.sh script to download the required files\n",
    "\n",
    "* _Load Sunlight data_: Sunlight data was downloaded from https://sunrise-sunset.org/, and it is downloaded/stored in this code\n",
    "\n",
    "* _Load Weather event data_: Weather events are downloaded dynamically from copernicus(default)/oikolab for specific lat and long. The copernicus data is obtained at 5km grid level, while oikolab can only be obtained at 25km level unless the user has a paid subscription.\n",
    "\n",
    "* _Construct Feature Vectors for pairs of City-Geohash_: This would be an initial feature csv that only contains time, traffic, and weather information "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:22.604907Z",
     "iopub.status.busy": "2025-04-27T02:37:22.604374Z",
     "iopub.status.idle": "2025-04-27T02:37:23.484216Z",
     "shell.execute_reply": "2025-04-27T02:37:23.483501Z"
    }
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count, Lock\n",
    "from urllib.request import Request, urlopen\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import requests\n",
    "import cdsapi\n",
    "import pprint\n",
    "import pytz\n",
    "import math\n",
    "import csv\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:23.487867Z",
     "iopub.status.busy": "2025-04-27T02:37:23.487611Z",
     "iopub.status.idle": "2025-04-27T02:37:23.495398Z",
     "shell.execute_reply": "2025-04-27T02:37:23.494902Z"
    }
   },
   "outputs": [],
   "source": [
    "from common import cities, city_keys, years, months\n",
    "\n",
    "# defaulting to 1st date for both\n",
    "start_date = pd.to_datetime(f\"{years[0]}-{months[0]}-01 00:00:00\")\n",
    "end_date = pd.to_datetime(f\"{years[-1]}-{months[-1]}-01 00:00:00\")\n",
    "if start_date == end_date:\n",
    "    end_date = pd.to_datetime(f\"{years[-1]}-{months[-1]}-02 00:00:00\")\n",
    "    month_ranges = [f\"{years[0]}-{months[0]}-01/{years[-1]}-{months[-1]}-02\"]\n",
    "else:\n",
    "    month_ranges = [ # costly requests can take longer, might as well get one month at a time...\n",
    "        (f'{d.strftime('%Y-%m-01')}/{(d + pd.offsets.MonthBegin(1)).strftime('%Y-%m-01')}')\n",
    "        for d in pd.date_range(start=start_date, end=end_date, freq='MS') if d < end_date\n",
    "    ]\n",
    "\n",
    "class W_MODEL_API:\n",
    "    OIKO = \"OIKO\"\n",
    "    ECMFW = \"ECMFW\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:23.497520Z",
     "iopub.status.busy": "2025-04-27T02:37:23.497398Z",
     "iopub.status.idle": "2025-04-27T02:37:23.501812Z",
     "shell.execute_reply": "2025-04-27T02:37:23.501391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-6-01/2018-6-02']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:23.554921Z",
     "iopub.status.busy": "2025-04-27T02:37:23.554738Z",
     "iopub.status.idle": "2025-04-27T02:37:23.561214Z",
     "shell.execute_reply": "2025-04-27T02:37:23.560588Z"
    }
   },
   "outputs": [],
   "source": [
    "dirs = ['../data', '../data/traffic', '../data/weather', '../data/input', '../data/sample_daylight']\n",
    "for dir in dirs:\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "load_dotenv(dotenv_path=os.path.abspath('../prod.env'))\n",
    "api_key = os.environ['OIKOLAB_API']\n",
    "url = 'https://api.oikolab.com/weather' # this is paid, use at your own discretion\n",
    "weather_model = W_MODEL_API.OIKO\n",
    "\n",
    "max_cores = len(city_keys) if len(city_keys) < cpu_count() else cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:23.563414Z",
     "iopub.status.busy": "2025-04-27T02:37:23.562820Z",
     "iopub.status.idle": "2025-04-27T02:37:24.027995Z",
     "shell.execute_reply": "2025-04-27T02:37:24.027376Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:37:24,023 INFO [2024-09-26T00:00:00] Watch our [Forum](https://forum.ecmwf.int/) for Announcements, news and other discussed topics.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:37:24,025 WARNING [2024-06-16T00:00:00] CDS API syntax is changed and some keys or parameter names may have also changed. To avoid requests failing, please use the \"Show API request code\" tool on the dataset Download Form to check you are using the correct syntax for your API request.\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(os.environ['HOME'],'.cdsapirc'), 'w') as file:\n",
    "    file.write(f'url: https://cds.climate.copernicus.eu/api\\n')\n",
    "    file.write(f'key: {os.environ['CDS_API']}\\n')\n",
    "\n",
    "\n",
    "weather_model = W_MODEL_API.ECMFW\n",
    "\n",
    "cdsClient = cdsapi.Client()\n",
    "\n",
    "# ecmwf_paramters = '141.128/164.128/165.128/166.128/167.128/228089.128/228090.128/228219.128'\n",
    "# [ # https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation#heading-Parameterlistings\n",
    "#     \"snow_depth\", #141 sd\n",
    "#     \"total_cloud_cover\", #164 tcc\n",
    "#     \"10m_u_component_of_wind\", #165 u10\n",
    "#     \"10m_v_component_of_wind\", #166 v10\n",
    "#     \"2m_temperature\", # 167 t2m\n",
    "#     \"total_column_rain_water\", #228089 tcrw\n",
    "#     \"total_column_snow_water\", #228089 tcsw\n",
    "#     \"large_scale_rain_rate\", #228219 lsrr\n",
    "#     \"large_scale_snowfall_rate_water_equivalent\" #228221 lssfr\n",
    "# ]\n",
    "\n",
    "ecmwf_variables = [\n",
    "    [\n",
    "        '2m_temperature',\n",
    "        '10m_u_component_of_wind',\n",
    "        '10m_v_component_of_wind',\n",
    "        'instantaneous_10m_wind_gust',\n",
    "        'snow_depth', \n",
    "        'total_cloud_cover'\n",
    "    ],\n",
    "    [\n",
    "        'total_precipitation'\n",
    "    ],\n",
    "    # [ # ignoring snowfall in favor of snow depth and precip?\n",
    "    #     'snowfall'\n",
    "    # ],\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sunrise Sunset Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:24.029752Z",
     "iopub.status.busy": "2025-04-27T02:37:24.029570Z",
     "iopub.status.idle": "2025-04-27T02:37:24.653011Z",
     "shell.execute_reply": "2025-04-27T02:37:24.652288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sample_daylight/Austin_2018601_2018601.csv.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sample_daylight/LosAngeles_2018601_2018601.csv.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/sample_daylight/NewYorkCity_2018601_2018601.csv.csv\n"
     ]
    }
   ],
   "source": [
    "for (city, city_vals) in cities.items():\n",
    "    file = open(f\"../data/sample_daylight/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv.csv\", \"w\")\n",
    "    wr_csv = csv.writer(file)\n",
    "    is_header = False\n",
    "    s_month = 1\n",
    "    for year in years:\n",
    "        s_end = months[-1] if (len(years) > 1 and years[-1] == year) or (len(years)==1) else 12\n",
    "        s_start = months[0] if (s_month==1) else 1\n",
    "        s_month = 0\n",
    "        for month in range(s_start, s_end+1, 1):\n",
    "            req = Request(\n",
    "                url = f'https://sunrise-sunset.org/us/{city_vals['sunrise']}/{year}/{month}', \n",
    "                headers={'User-Agent': 'Mozilla/5.0'} # weirdly enough we get auth errors w/o this??\n",
    "            )\n",
    "            html = urlopen(req).read()\n",
    "            soup =  BeautifulSoup(html)\n",
    "            for span in soup.find_all(\"span\", {'class':'tooltip'}): \n",
    "                span.decompose()\n",
    "            \n",
    "            table = soup.select_one(\"table#month\")\n",
    "\n",
    "            if not is_header:\n",
    "                th_all = table.select(\"tr.headers th\")\n",
    "                headers = [th.text for th in th_all]\n",
    "                headers.append('Cities')\n",
    "                wr_csv.writerow(headers)\n",
    "                is_header = True\n",
    "            \n",
    "            tr_all = table.select(\"tr.day\")\n",
    "            day = 1\n",
    "            for tr in tr_all:\n",
    "                td_all = [td.text for td in tr.select(\"th,td\")]\n",
    "                td_all[0] = f'{year}-{month}-{day}'\n",
    "                day += 1\n",
    "                td_all.append(city)\n",
    "                wr_csv.writerow(td_all)\n",
    "\n",
    "    print(file.name)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the traffic events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:37:24.656023Z",
     "iopub.status.busy": "2025-04-27T02:37:24.655694Z",
     "iopub.status.idle": "2025-04-27T02:38:54.730373Z",
     "shell.execute_reply": "2025-04-27T02:38:54.728807Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events = pd.read_csv('../TrafficEvents_Aug16_Dec20_Publish.csv') # This is the latest version of LSTW dataset\n",
    "# get the data from https://smoosavi.org/datasets/lstw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:38:54.735418Z",
     "iopub.status.busy": "2025-04-27T02:38:54.735072Z",
     "iopub.status.idle": "2025-04-27T02:39:27.631655Z",
     "shell.execute_reply": "2025-04-27T02:39:27.630815Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events['StartTime(UTC)'] = pd.to_datetime(t_events['StartTime(UTC)'], utc=True)\n",
    "t_events['EndTime(UTC)'] = pd.to_datetime(t_events['EndTime(UTC)'], utc=True)\n",
    "t_events['StartTime'] = t_events['StartTime(UTC)']\n",
    "t_events['EndTime'] = t_events['EndTime(UTC)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:27.634095Z",
     "iopub.status.busy": "2025-04-27T02:39:27.633901Z",
     "iopub.status.idle": "2025-04-27T02:39:32.623204Z",
     "shell.execute_reply": "2025-04-27T02:39:32.621930Z"
    }
   },
   "outputs": [],
   "source": [
    "t_events = t_events[(t_events['StartTime(UTC)'] >= start_date.tz_localize('UTC')) & (t_events['EndTime(UTC)'] < end_date.tz_localize('UTC'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:32.626351Z",
     "iopub.status.busy": "2025-04-27T02:39:32.626118Z",
     "iopub.status.idle": "2025-04-27T02:39:32.653285Z",
     "shell.execute_reply": "2025-04-27T02:39:32.652845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EventId</th>\n",
       "      <th>Type</th>\n",
       "      <th>Severity</th>\n",
       "      <th>TMC</th>\n",
       "      <th>Description</th>\n",
       "      <th>StartTime(UTC)</th>\n",
       "      <th>EndTime(UTC)</th>\n",
       "      <th>TimeZone</th>\n",
       "      <th>LocationLat</th>\n",
       "      <th>LocationLng</th>\n",
       "      <th>...</th>\n",
       "      <th>AirportCode</th>\n",
       "      <th>Number</th>\n",
       "      <th>Street</th>\n",
       "      <th>Side</th>\n",
       "      <th>City</th>\n",
       "      <th>County</th>\n",
       "      <th>State</th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23170440</th>\n",
       "      <td>T-23772103</td>\n",
       "      <td>Construction</td>\n",
       "      <td>3</td>\n",
       "      <td>500</td>\n",
       "      <td>Right lane closed due to bridge maintenance wo...</td>\n",
       "      <td>2018-06-01 00:00:00+00:00</td>\n",
       "      <td>2018-06-01 10:00:00+00:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>42.884033</td>\n",
       "      <td>-78.768097</td>\n",
       "      <td>...</td>\n",
       "      <td>KBUF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>William St</td>\n",
       "      <td>R</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Erie</td>\n",
       "      <td>NY</td>\n",
       "      <td>14227.0</td>\n",
       "      <td>2018-06-01 00:00:00+00:00</td>\n",
       "      <td>2018-06-01 10:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23170441</th>\n",
       "      <td>T-23772104</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>Severe delays of 21 minutes on NY-263 Millersp...</td>\n",
       "      <td>2018-06-01 01:24:00+00:00</td>\n",
       "      <td>2018-06-01 02:05:19+00:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>42.973011</td>\n",
       "      <td>-78.804932</td>\n",
       "      <td>...</td>\n",
       "      <td>KBUF</td>\n",
       "      <td>672.0</td>\n",
       "      <td>Millersport Hwy</td>\n",
       "      <td>L</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>Erie</td>\n",
       "      <td>NY</td>\n",
       "      <td>14226.0</td>\n",
       "      <td>2018-06-01 01:24:00+00:00</td>\n",
       "      <td>2018-06-01 02:05:19+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23171534</th>\n",
       "      <td>T-23773197</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>Delays of five minutes on I-95 Northbound betw...</td>\n",
       "      <td>2018-06-01 00:25:00+00:00</td>\n",
       "      <td>2018-06-01 01:07:57+00:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>41.873222</td>\n",
       "      <td>-71.385422</td>\n",
       "      <td>...</td>\n",
       "      <td>KSFZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I-95 N</td>\n",
       "      <td>R</td>\n",
       "      <td>Pawtucket</td>\n",
       "      <td>Providence</td>\n",
       "      <td>RI</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>2018-06-01 00:25:00+00:00</td>\n",
       "      <td>2018-06-01 01:07:57+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23171535</th>\n",
       "      <td>T-23773198</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>Delays of two minutes on Huntington Ave Westbo...</td>\n",
       "      <td>2018-06-01 00:37:00+00:00</td>\n",
       "      <td>2018-06-01 01:19:04+00:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>42.347919</td>\n",
       "      <td>-71.078690</td>\n",
       "      <td>...</td>\n",
       "      <td>KBOS</td>\n",
       "      <td>168.0</td>\n",
       "      <td>Exeter St</td>\n",
       "      <td>L</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>MA</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>2018-06-01 00:37:00+00:00</td>\n",
       "      <td>2018-06-01 01:19:04+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23171536</th>\n",
       "      <td>T-23773199</td>\n",
       "      <td>Congestion</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>Delays of three minutes on Pilgrims Hwy Northb...</td>\n",
       "      <td>2018-06-01 00:48:00+00:00</td>\n",
       "      <td>2018-06-01 01:32:03+00:00</td>\n",
       "      <td>US/Eastern</td>\n",
       "      <td>41.977509</td>\n",
       "      <td>-70.712250</td>\n",
       "      <td>...</td>\n",
       "      <td>KPYM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MA-3 N</td>\n",
       "      <td>R</td>\n",
       "      <td>Kingston</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>MA</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>2018-06-01 00:48:00+00:00</td>\n",
       "      <td>2018-06-01 01:32:03+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EventId          Type  Severity  TMC  \\\n",
       "23170440  T-23772103  Construction         3  500   \n",
       "23170441  T-23772104    Congestion         2   70   \n",
       "23171534  T-23773197    Congestion         2   72   \n",
       "23171535  T-23773198    Congestion         1   70   \n",
       "23171536  T-23773199    Congestion         1   73   \n",
       "\n",
       "                                                Description  \\\n",
       "23170440  Right lane closed due to bridge maintenance wo...   \n",
       "23170441  Severe delays of 21 minutes on NY-263 Millersp...   \n",
       "23171534  Delays of five minutes on I-95 Northbound betw...   \n",
       "23171535  Delays of two minutes on Huntington Ave Westbo...   \n",
       "23171536  Delays of three minutes on Pilgrims Hwy Northb...   \n",
       "\n",
       "                    StartTime(UTC)              EndTime(UTC)    TimeZone  \\\n",
       "23170440 2018-06-01 00:00:00+00:00 2018-06-01 10:00:00+00:00  US/Eastern   \n",
       "23170441 2018-06-01 01:24:00+00:00 2018-06-01 02:05:19+00:00  US/Eastern   \n",
       "23171534 2018-06-01 00:25:00+00:00 2018-06-01 01:07:57+00:00  US/Eastern   \n",
       "23171535 2018-06-01 00:37:00+00:00 2018-06-01 01:19:04+00:00  US/Eastern   \n",
       "23171536 2018-06-01 00:48:00+00:00 2018-06-01 01:32:03+00:00  US/Eastern   \n",
       "\n",
       "          LocationLat  LocationLng  ...  AirportCode Number           Street  \\\n",
       "23170440    42.884033   -78.768097  ...         KBUF    NaN       William St   \n",
       "23170441    42.973011   -78.804932  ...         KBUF  672.0  Millersport Hwy   \n",
       "23171534    41.873222   -71.385422  ...         KSFZ    NaN           I-95 N   \n",
       "23171535    42.347919   -71.078690  ...         KBOS  168.0        Exeter St   \n",
       "23171536    41.977509   -70.712250  ...         KPYM    NaN           MA-3 N   \n",
       "\n",
       "         Side       City      County State  ZipCode                 StartTime  \\\n",
       "23170440    R    Buffalo        Erie    NY  14227.0 2018-06-01 00:00:00+00:00   \n",
       "23170441    L    Buffalo        Erie    NY  14226.0 2018-06-01 01:24:00+00:00   \n",
       "23171534    R  Pawtucket  Providence    RI   2860.0 2018-06-01 00:25:00+00:00   \n",
       "23171535    L     Boston     Suffolk    MA   2116.0 2018-06-01 00:37:00+00:00   \n",
       "23171536    R   Kingston    Plymouth    MA   2364.0 2018-06-01 00:48:00+00:00   \n",
       "\n",
       "                           EndTime  \n",
       "23170440 2018-06-01 10:00:00+00:00  \n",
       "23170441 2018-06-01 02:05:19+00:00  \n",
       "23171534 2018-06-01 01:07:57+00:00  \n",
       "23171535 2018-06-01 01:19:04+00:00  \n",
       "23171536 2018-06-01 01:32:03+00:00  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the traffic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:32.655160Z",
     "iopub.status.busy": "2025-04-27T02:39:32.654884Z",
     "iopub.status.idle": "2025-04-27T02:39:32.661089Z",
     "shell.execute_reply": "2025-04-27T02:39:32.660535Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subset(city_vals):\n",
    "    tzone = pytz.timezone(city_vals['timezone'])\n",
    "    crds = city_vals['coordinates']\n",
    "    \n",
    "    subset_all = t_events[(t_events['LocationLat']>crds[0]) & (t_events['LocationLat']<crds[2]) & (t_events['LocationLng']>crds[1]) & \n",
    "                    (t_events['LocationLng']<crds[3])]\n",
    "    subset_all['StartTime'].dt.tz_convert(tzone)\n",
    "    subset_all['EndTime'].dt.tz_convert(tzone)\n",
    "    subset_all = subset_all.copy()\n",
    "    subset_all['Type'] = subset_all['Type'].str.replace('-', '')\n",
    "    \n",
    "    subset_accidents = subset_all[(subset_all['Type']=='Accident')]\n",
    "\n",
    "    return subset_all, subset_accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:32.662520Z",
     "iopub.status.busy": "2025-04-27T02:39:32.662355Z",
     "iopub.status.idle": "2025-04-27T02:39:32.666126Z",
     "shell.execute_reply": "2025-04-27T02:39:32.665720Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_traffic(city):\n",
    "    city_vals = cities[city]\n",
    "    subset_all, subset_accidents = get_subset(city_vals)\n",
    "    subset_all.to_csv(f'../data/traffic/TD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv', index=False)\n",
    "    if len(subset_all):\n",
    "        print(f'For {city} we have {len(subset_all)} incidents, with {len(subset_accidents)} accidents! ratio {len(subset_accidents)*1.0/len(subset_all):.2f}')\n",
    "    return subset_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:32.667463Z",
     "iopub.status.busy": "2025-04-27T02:39:32.667305Z",
     "iopub.status.idle": "2025-04-27T02:39:33.306807Z",
     "shell.execute_reply": "2025-04-27T02:39:33.306247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For LosAngeles we have 1461 incidents, with 90 accidents! ratio 0.06"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For NewYorkCity we have 1806 incidents, with 45 accidents! ratio 0.02"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Austin we have 339 incidents, with 65 accidents! ratio 0.19"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tt_events = {}\n",
    "with Pool(max_cores) as p:\n",
    "    for i, event in enumerate(p.map(clean_traffic, city_keys)):\n",
    "        tt_events[city_keys[i]] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.308950Z",
     "iopub.status.busy": "2025-04-27T02:39:33.308782Z",
     "iopub.status.idle": "2025-04-27T02:39:33.324228Z",
     "shell.execute_reply": "2025-04-27T02:39:33.323817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             EventId           Type  Severity  TMC  \\\n",
      "23192398  T-23794067     Congestion         1   74   \n",
      "23192399  T-23794068  BrokenVehicle         2  211   \n",
      "\n",
      "                                                Description  \\\n",
      "23192398  Delays of one minute on I-35 Southbound betwee...   \n",
      "23192399  Stalled vehicle on Lamar Blvd Northbound at 39...   \n",
      "\n",
      "                    StartTime(UTC)              EndTime(UTC)    TimeZone  \\\n",
      "23192398 2018-06-01 00:03:00+00:00 2018-06-01 00:46:43+00:00  US/Central   \n",
      "23192399 2018-06-01 00:07:41+00:00 2018-06-01 00:37:28+00:00  US/Central   \n",
      "\n",
      "          LocationLat  LocationLng  ...  AirportCode  Number        Street  \\\n",
      "23192398    30.173191   -97.782196  ...         KATT     NaN        I-35 S   \n",
      "23192399    30.306252   -97.742386  ...         KATT  3901.0  N Lamar Blvd   \n",
      "\n",
      "         Side    City  County State  ZipCode                 StartTime  \\\n",
      "23192398    R  Austin  Travis    TX  78745.0 2018-06-01 00:03:00+00:00   \n",
      "23192399    R  Austin  Travis    TX  78751.0 2018-06-01 00:07:41+00:00   \n",
      "\n",
      "                           EndTime  \n",
      "23192398 2018-06-01 00:46:43+00:00  \n",
      "23192399 2018-06-01 00:37:28+00:00  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "             EventId         Type  Severity  TMC  \\\n",
      "23203376  T-23805047  LaneBlocked         3  520   \n",
      "23203392  T-23805063   Congestion         1   70   \n",
      "\n",
      "                                                Description  \\\n",
      "23203376  Slow lane blocked due to stalled vehicle on I-...   \n",
      "23203392  Delays of one minute on Artesia Blvd Eastbound...   \n",
      "\n",
      "                    StartTime(UTC)              EndTime(UTC)    TimeZone  \\\n",
      "23203376 2018-06-01 00:00:35+00:00 2018-06-01 00:30:15+00:00  US/Pacific   \n",
      "23203392 2018-06-01 00:00:00+00:00 2018-06-01 00:44:16+00:00  US/Pacific   \n",
      "\n",
      "          LocationLat  LocationLng  ...  AirportCode Number          Street  \\\n",
      "23203376    34.034954  -118.333710  ...         KSMO    NaN          I-10 E   \n",
      "23203392    33.872822  -118.299141  ...         KHHR    NaN  W Artesia Blvd   \n",
      "\n",
      "         Side         City       County State  ZipCode  \\\n",
      "23203376    R  Los Angeles  Los Angeles    CA  90016.0   \n",
      "23203392    R      Gardena  Los Angeles    CA  90248.0   \n",
      "\n",
      "                         StartTime                   EndTime  \n",
      "23203376 2018-06-01 00:00:35+00:00 2018-06-01 00:30:15+00:00  \n",
      "23203392 2018-06-01 00:00:00+00:00 2018-06-01 00:44:16+00:00  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "             EventId        Type  Severity  TMC  \\\n",
      "23177054  T-23778718  Congestion         1   73   \n",
      "23177055  T-23778719  Congestion         2   72   \n",
      "\n",
      "                                                Description  \\\n",
      "23177054  Delays of one minute on Brooklyn Queens Expy W...   \n",
      "23177055  Delays of nine minutes on Long Island Expy Eas...   \n",
      "\n",
      "                    StartTime(UTC)              EndTime(UTC)    TimeZone  \\\n",
      "23177054 2018-06-01 00:00:00+00:00 2018-06-01 00:41:30+00:00  US/Eastern   \n",
      "23177055 2018-06-01 00:04:00+00:00 2018-06-01 00:45:41+00:00  US/Eastern   \n",
      "\n",
      "          LocationLat  LocationLng  ...  AirportCode Number  \\\n",
      "23177054    40.673096   -73.999527  ...         KJRB    NaN   \n",
      "23177055    40.737881   -73.849976  ...         KLGA    NaN   \n",
      "\n",
      "                      Street Side          City  County State  ZipCode  \\\n",
      "23177054      Gowanus Expy W    R      Brooklyn   Kings    NY  11231.0   \n",
      "23177055  Long Island Expy E    R  Forest Hills  Queens    NY  11375.0   \n",
      "\n",
      "                         StartTime                   EndTime  \n",
      "23177054 2018-06-01 00:00:00+00:00 2018-06-01 00:41:30+00:00  \n",
      "23177055 2018-06-01 00:04:00+00:00 2018-06-01 00:45:41+00:00  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "for city in city_keys:\n",
    "    pprint.pprint(tt_events[city].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.325618Z",
     "iopub.status.busy": "2025-04-27T02:39:33.325488Z",
     "iopub.status.idle": "2025-04-27T02:39:33.327705Z",
     "shell.execute_reply": "2025-04-27T02:39:33.327453Z"
    }
   },
   "outputs": [],
   "source": [
    "del t_events # major abuser of memory removed??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.329139Z",
     "iopub.status.busy": "2025-04-27T02:39:33.328796Z",
     "iopub.status.idle": "2025-04-27T02:39:33.334938Z",
     "shell.execute_reply": "2025-04-27T02:39:33.334566Z"
    }
   },
   "outputs": [],
   "source": [
    "class OIKO:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "\n",
    "    def get_weather_data(self, sdate, edate):\n",
    "        lat = []\n",
    "        long = []\n",
    "        city_vals = cities[self.city]\n",
    "\n",
    "        for (la, lo) in city_vals['weather']:\n",
    "            lat.append(la)\n",
    "            long.append(lo)\n",
    "        \n",
    "        response = requests.get(url,\n",
    "            params={'param': ['temperature', '10m_wind_gust', 'relative_humidity', 'wind_speed', 'wind_direction', 'total_cloud_cover', 'total_precipitation', 'snowfall'],\n",
    "                    'lat': lat,\n",
    "                    'lon': long,\n",
    "                    'start': sdate,\n",
    "                    'end': edate,\n",
    "                    'format': 'csv'},\n",
    "                    headers={'api-key': api_key}\n",
    "            )\n",
    "        \n",
    "        output = None\n",
    "        with tempfile.NamedTemporaryFile(mode='w+', delete=True) as tmp:\n",
    "            tmp.write(response.text)\n",
    "            output = pd.read_csv(tmp.name)\n",
    "            \n",
    "        \n",
    "        return output\n",
    "\n",
    "    def sample_weather(self):\n",
    "        tzone = pytz.timezone(cities[self.city]['timezone'])\n",
    "        traffic = pd.read_csv(f'../data/traffic/TD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "        if (len(traffic) == 0):\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # since weather is obtained based on utc, we use utc. shouldn't matter if the local time is different\n",
    "        traffic['StartTime(UTC)'] = pd.to_datetime(traffic['StartTime(UTC)'])\n",
    "        traffic = traffic.sort_values('StartTime(UTC)').set_index('StartTime(UTC)')\n",
    "        f_out = self.get_weather_data(traffic.index.min().date(), traffic.index.max().date())\n",
    "        f_out.columns = [col.partition(' ')[0] for col in f_out.columns] # ignore the suffix in col names\n",
    "        f_out['datetime'] = pd.to_datetime(f_out['datetime'], utc=True)\n",
    "        f_out['datetime(UTC)'] = f_out['datetime']\n",
    "        f_out['datetime'].dt.tz_convert(tzone)\n",
    "        f_out[['LocationLat', 'LocationLng']] = f_out['coordinates'].apply(lambda x: pd.Series(ast.literal_eval(x)) if isinstance(x, str) else pd.Series(x) if isinstance(x, (list, tuple)) and len(x) == 2 else pd.Series([None, None]))\n",
    "        f_out.drop(columns=['coordinates'], inplace=True)\n",
    "        f_out.to_csv(f'../data/weather/WD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "        return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.336265Z",
     "iopub.status.busy": "2025-04-27T02:39:33.336088Z",
     "iopub.status.idle": "2025-04-27T02:39:33.341006Z",
     "shell.execute_reply": "2025-04-27T02:39:33.340649Z"
    }
   },
   "outputs": [],
   "source": [
    "class ECMWF:\n",
    "    def __init__(self, city):\n",
    "        self.city = city\n",
    "\n",
    "    def get_weather_data(self):\n",
    "        coords = cities[self.city]['coordinates']\n",
    "        datasets = []\n",
    "        output_nc = []\n",
    "        output_dirs = []\n",
    "        index = 0\n",
    "        for date in month_ranges:\n",
    "            curr_var_set = []\n",
    "            for vars in ecmwf_variables:\n",
    "                output_dirs.append(tempfile.TemporaryDirectory(delete=True))\n",
    "                output_nc.append(os.path.join(output_dirs[index].name, f'era5_data{index}.nc'))\n",
    "                cdsClient.retrieve(\n",
    "                    'reanalysis-era5-single-levels',\n",
    "                    {\n",
    "                        'product_type': 'reanalysis',\n",
    "                        'format': 'netcdf',\n",
    "                        'variable': vars,\n",
    "                        'date': date,\n",
    "                        'time': '00/to/23/by/1',\n",
    "                        'area': coords,\n",
    "                        'grid': [0.05, 0.05],\n",
    "                        'data_format': 'netcdf'\n",
    "                    },\n",
    "                    output_nc[index]\n",
    "                )\n",
    "                curr_var_set.append(xr.open_dataset(output_nc[index], engine='netcdf4').load())\n",
    "                index += 1\n",
    "            \n",
    "            \n",
    "            datasets.append(xr.merge(curr_var_set))\n",
    "            del curr_var_set\n",
    "        \n",
    "        df = (xr.merge(datasets)).to_dataframe().reset_index()\n",
    "        for i in range(len(ecmwf_variables)*len(month_ranges)):\n",
    "            if i < len(output_nc):\n",
    "                os.remove(output_nc[i])\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        del datasets\n",
    "        return df\n",
    "\n",
    "    def sample_weather(self):\n",
    "        tzone = pytz.timezone(cities[self.city]['timezone'])\n",
    "        f_out = self.get_weather_data()\n",
    "        f_out['time'] = pd.to_datetime(f_out['valid_time'], utc=True)\n",
    "        f_out['time(UTC)'] = f_out['time']\n",
    "        f_out['time'].dt.tz_convert(tzone)\n",
    "        f_out.to_csv(f'../data/weather/WD_{self.city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv', index=False)\n",
    "        return f_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.342305Z",
     "iopub.status.busy": "2025-04-27T02:39:33.342090Z",
     "iopub.status.idle": "2025-04-27T02:39:33.344800Z",
     "shell.execute_reply": "2025-04-27T02:39:33.344433Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_weather_api(city):\n",
    "    if weather_model == W_MODEL_API.OIKO:\n",
    "        # for unit of measurements please refer https://docs.oikolab.com/parameters/\n",
    "        return OIKO(city)\n",
    "    else:\n",
    "        # rate limited to one request per user, so might as well perform single threaded operation\n",
    "        # for unit of measurements please refer https://cds.climate.copernicus.eu/datasets\n",
    "        return ECMWF(city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.346604Z",
     "iopub.status.busy": "2025-04-27T02:39:33.346001Z",
     "iopub.status.idle": "2025-04-27T02:39:33.349093Z",
     "shell.execute_reply": "2025-04-27T02:39:33.348647Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_weather(city):\n",
    "    return get_weather_api(city).sample_weather()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:39:33.350822Z",
     "iopub.status.busy": "2025-04-27T02:39:33.350445Z",
     "iopub.status.idle": "2025-04-27T02:41:18.818723Z",
     "shell.execute_reply": "2025-04-27T02:41:18.818023Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,433 INFO Request ID is 4383b546-71ac-4c6a-9c22-19903f88e6b0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,494 INFO Request ID is 148403f6-92dc-4922-8eb7-0081e1423841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,558 INFO Request ID is fecd2ec1-7843-45bf-8a32-23d9967ee47d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,567 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,615 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:39:34,672 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:07,577 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "a7af0982f1534500fbec1b1f2590f48c.nc:   0%|          | 0.00/163k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "a7af0982f1534500fbec1b1f2590f48c.nc: 100%|██████████| 163k/163k [00:00<00:00, 193kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:10,243 INFO Request ID is 433ef33a-6640-4515-b26b-c616cb4cb60e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:10,368 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:25,072 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:25,188 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "358424850f085a00f24c6c66153e8a41.nc:   0%|          | 0.00/128k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "1c14efed11e6baef3c0323504a278ced.nc:   0%|          | 0.00/127k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "358424850f085a00f24c6c66153e8a41.nc: 100%|██████████| 128k/128k [00:00<00:00, 196kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "1c14efed11e6baef3c0323504a278ced.nc: 100%|██████████| 127k/127k [00:00<00:00, 188kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:26,880 INFO Request ID is 2888ea43-358a-492c-9852-4c7d6db5cb7b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:26,996 INFO Request ID is 6911c3f5-ee16-47bc-bb92-3dc95237881e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:26,999 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:27,130 INFO status has been updated to accepted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:31,860 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "f6523a3ccb77eccb2d6b15e2db781a23.nc:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "f6523a3ccb77eccb2d6b15e2db781a23.nc: 100%|██████████| 25.1k/25.1k [00:00<00:00, 62.2kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:40:48,520 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "4319e213270cacf5b453394e893e0512.nc:   0%|          | 0.00/29.1k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "4319e213270cacf5b453394e893e0512.nc: 100%|██████████| 29.1k/29.1k [00:00<00:00, 76.5kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 22:41:17,532 INFO status has been updated to successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "c52f3f9750594d082a7a2884c5b4b8c7.nc:   0%|          | 0.00/37.3k [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "c52f3f9750594d082a7a2884c5b4b8c7.nc: 100%|██████████| 37.3k/37.3k [00:00<00:00, 97.2kB/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "wt_events = {}\n",
    "with Pool(max_cores) as p:\n",
    "    for i, event in enumerate(p.map(sample_weather, city_keys)):\n",
    "        wt_events[city_keys[i]] = event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.821892Z",
     "iopub.status.busy": "2025-04-27T02:41:18.821666Z",
     "iopub.status.idle": "2025-04-27T02:41:18.833537Z",
     "shell.execute_reply": "2025-04-27T02:41:18.833119Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin   valid_time  latitude  longitude  number expver         t2m       u10  \\\n",
      "0 2018-06-01     30.58 -97.969000       0   0001  308.433960 -1.322009   \n",
      "1 2018-06-01     30.58 -97.918889       0   0001  308.439453 -1.372577   \n",
      "\n",
      "        v10      i10fg   sd  tcc   tp                      time  \\\n",
      "0  5.416805  11.530937  0.0  0.0  0.0 2018-06-01 00:00:00+00:00   \n",
      "1  5.544582  11.665062  0.0  0.0  0.0 2018-06-01 00:00:00+00:00   \n",
      "\n",
      "                  time(UTC)  \n",
      "0 2018-06-01 00:00:00+00:00  \n",
      "1 2018-06-01 00:00:00+00:00  \n",
      "LosAngeles   valid_time  latitude   longitude  number expver         t2m       u10  \\\n",
      "0 2018-06-01    34.351 -118.684000       0   0001  292.797974  1.501770   \n",
      "1 2018-06-01    34.351 -118.633917       0   0001  292.928711  1.419983   \n",
      "\n",
      "        v10      i10fg   sd       tcc   tp                      time  \\\n",
      "0  2.966491  10.231727  0.0  0.023943  0.0 2018-06-01 00:00:00+00:00   \n",
      "1  3.082701  10.348365  0.0  0.024296  0.0 2018-06-01 00:00:00+00:00   \n",
      "\n",
      "                  time(UTC)  \n",
      "0 2018-06-01 00:00:00+00:00  \n",
      "1 2018-06-01 00:00:00+00:00  \n",
      "NewYorkCity   valid_time  latitude  longitude  number expver         t2m       u10  \\\n",
      "0 2018-06-01    40.878 -74.260000       0   0001  293.191772 -2.447965   \n",
      "1 2018-06-01    40.878 -74.209909       0   0001  293.130737 -2.483258   \n",
      "\n",
      "        v10     i10fg   sd  tcc        tp                      time  \\\n",
      "0  1.017128  5.507339  0.0  1.0  0.000039 2018-06-01 00:00:00+00:00   \n",
      "1  1.022224  5.531356  0.0  1.0  0.000037 2018-06-01 00:00:00+00:00   \n",
      "\n",
      "                  time(UTC)  \n",
      "0 2018-06-01 00:00:00+00:00  \n",
      "1 2018-06-01 00:00:00+00:00  \n"
     ]
    }
   ],
   "source": [
    "for city in city_keys:\n",
    "    print(city, wt_events[city].head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate final input csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.836077Z",
     "iopub.status.busy": "2025-04-27T02:41:18.835882Z",
     "iopub.status.idle": "2025-04-27T02:41:18.840842Z",
     "shell.execute_reply": "2025-04-27T02:41:18.840353Z"
    }
   },
   "outputs": [],
   "source": [
    "ttype_dict = {\n",
    "    'Construction': 0, # let's ignore insig events atm\n",
    "    'Event': 1,\n",
    "    'FlowIncident': 2,\n",
    "    'LaneBlocked': 3,\n",
    "    'BrokenVehicle': 4,\n",
    "    'Congestion': 5,\n",
    "    'Accident': 6\n",
    "}\n",
    "\n",
    "class Traffic_Event:\n",
    "    Severity: int = 0\n",
    "    StartTime: datetime = None\n",
    "    EndTime: datetime = None\n",
    "    LocationLat: float = 0\n",
    "    LocationLng: float = 0\n",
    "    Type: int = -1\n",
    "    # Accident: int = 0\n",
    "    # BrokenVehicle: int  = 0\n",
    "    # Congestion: int  = 0\n",
    "    # Construction: int  = 0\n",
    "    # Event: int  = 0\n",
    "    # FlowIncident: int  = 0\n",
    "    # LaneBlocked: int  = 0\n",
    "\n",
    "    def __init__(self, trafficRow, weatherRow, daylightRow):\n",
    "        self.Type = ttype_dict[trafficRow['Type']]\n",
    "        if (self.Type < 2):\n",
    "            return\n",
    "        self.StartTime = trafficRow['StartTime']\n",
    "        self.EndTime = trafficRow['EndTime']\n",
    "        self.Sunrise = daylightRow['Twilight Start'].time()\n",
    "        self.Sunset = daylightRow['Twilight End'].time()\n",
    "        # self.Severity = trafficRow['Severity'] # we can't predict severity, so it's alright i guess??\n",
    "        if (weather_model == W_MODEL_API.OIKO):\n",
    "            self.Snowfall = weatherRow['snowfall']\n",
    "            self.Precipitation = weatherRow['total_precipitation']\n",
    "            self.CloudCover = weatherRow['total_cloud_cover']\n",
    "            self.WindDirection = weatherRow['wind_direction']\n",
    "            self.WindSpeed = weatherRow['wind_speed']\n",
    "            self.RelativeHumidity = weatherRow['relative_humidity']\n",
    "            self.WindGust = weatherRow['10m_wind_gust']\n",
    "            self.Temperature = weatherRow['temperature']\n",
    "\n",
    "            ### I urge you to modify our code to make these parts work. We are only using ECMWF, so you might have to manually fix the grid\n",
    "            self.LocationLat = trafficRow['LocationLat']\n",
    "            self.LocationLng = trafficRow['LocationLng']\n",
    "        else:\n",
    "            self.LocationLat = weatherRow['latitude'] # closest 5km grid lat\n",
    "            self.LocationLng = weatherRow['longitude'] # closest 5km grid lng\n",
    "            self.SnowDept = weatherRow['sd']\n",
    "            # if 'sf' in weatherRow:\n",
    "            #     self.SnowFall = weatherRow['sf']\n",
    "            self.CloudCover = weatherRow['tcc']\n",
    "            self.UWind = weatherRow['u10']\n",
    "            self.VWind = weatherRow['v10']\n",
    "            if 'i10fg' in weatherRow:\n",
    "                self.Gust = weatherRow['i10fg']\n",
    "            self.Temperature = weatherRow['t2m']\n",
    "            if 'tp' in weatherRow:\n",
    "                self.Precipitation = weatherRow['tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.842882Z",
     "iopub.status.busy": "2025-04-27T02:41:18.842661Z",
     "iopub.status.idle": "2025-04-27T02:41:18.845590Z",
     "shell.execute_reply": "2025-04-27T02:41:18.845123Z"
    }
   },
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "\n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return 6371000 * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.847049Z",
     "iopub.status.busy": "2025-04-27T02:41:18.846939Z",
     "iopub.status.idle": "2025-04-27T02:41:18.849191Z",
     "shell.execute_reply": "2025-04-27T02:41:18.848857Z"
    }
   },
   "outputs": [],
   "source": [
    "file_lock = Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.850661Z",
     "iopub.status.busy": "2025-04-27T02:41:18.850552Z",
     "iopub.status.idle": "2025-04-27T02:41:18.853052Z",
     "shell.execute_reply": "2025-04-27T02:41:18.852705Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_file(path, events: pd.DataFrame):\n",
    "    with file_lock:\n",
    "        if os.path.exists(path):\n",
    "            curr_events = pd.read_csv(path)\n",
    "            pd.concat([events, curr_events], ignore_index=True).to_csv(path, index=False)\n",
    "        else:\n",
    "            events.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.854804Z",
     "iopub.status.busy": "2025-04-27T02:41:18.854460Z",
     "iopub.status.idle": "2025-04-27T02:41:18.920103Z",
     "shell.execute_reply": "2025-04-27T02:41:18.919642Z"
    }
   },
   "outputs": [],
   "source": [
    "tt_events = {}\n",
    "wt_events = {}\n",
    "dl_events = {}\n",
    "for city in city_keys:\n",
    "    d_curr = pd.read_csv(f\"../data/sample_daylight/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv.csv\")\n",
    "    d_curr['Twilight Start'] = pd.to_datetime(d_curr['Twilight Start'], format='%I:%M:%S %p')\n",
    "    d_curr['Twilight End'] = pd.to_datetime(d_curr['Twilight End'], format='%I:%M:%S %p')\n",
    "    d_curr['Day'] = pd.to_datetime(d_curr['Day'])\n",
    "    t_curr = pd.read_csv(f'../data/traffic/TD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "    t_curr['StartTime(UTC)'] = pd.to_datetime(t_curr['StartTime(UTC)'], utc=True)\n",
    "    t_curr['EndTime(UTC)'] = pd.to_datetime(t_curr['EndTime(UTC)'], utc=True)\n",
    "    w_curr = pd.read_csv(f'../data/weather/WD_{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv')\n",
    "    w_curr['time(UTC)'] = pd.to_datetime(w_curr['time(UTC)'], utc=True)\n",
    "    tt_events[city] = t_curr\n",
    "    wt_events[city] = w_curr\n",
    "    dl_events[city] = d_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.922691Z",
     "iopub.status.busy": "2025-04-27T02:41:18.922563Z",
     "iopub.status.idle": "2025-04-27T02:41:18.927016Z",
     "shell.execute_reply": "2025-04-27T02:41:18.926473Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_input(args):\n",
    "    city = args[0]\n",
    "    t_curr = tt_events[city]\n",
    "    w_curr = wt_events[city]\n",
    "    d_curr = dl_events[city]\n",
    "    t_curr['StartTime(UTC)'] = t_curr['StartTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0, microsecond=0))\n",
    "    t_curr['EndTime(UTC)'] = t_curr['EndTime(UTC)'].apply(lambda x: x.replace(minute=0, second=0, microsecond=0))\n",
    "    start_i = args[1]\n",
    "    end_i = args[2]\n",
    "    file = args[3]\n",
    "    \n",
    "    events = []\n",
    "    for index, row in t_curr.iterrows():\n",
    "        if index < start_i:\n",
    "            continue\n",
    "        elif index >= end_i:\n",
    "            break\n",
    "\n",
    "        d_match = d_curr[(d_curr['Day'].dt.date == row['StartTime(UTC)'].date())]\n",
    "        w_match = w_curr[(w_curr['time(UTC)'] == row['StartTime(UTC)'])].copy()\n",
    "        w_match['distance'] = haversine(w_match['latitude'], w_match['longitude'], row['LocationLat'], row['LocationLng'])\n",
    "        if w_match.empty or d_match.empty:\n",
    "            continue\n",
    "        \n",
    "        w_match = w_match[w_match['distance'].min() == w_match['distance']].iloc[0]\n",
    "        te = Traffic_Event(row, w_match, d_match.iloc[0])\n",
    "        if te.Type < 2:\n",
    "            continue\n",
    "        events.append(vars(te))\n",
    "    \n",
    "    write_file(file, pd.DataFrame(events))\n",
    "    del events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:18.928623Z",
     "iopub.status.busy": "2025-04-27T02:41:18.928502Z",
     "iopub.status.idle": "2025-04-27T02:41:29.100670Z",
     "shell.execute_reply": "2025-04-27T02:41:29.100128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Austin 113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LosAngeles 98\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewYorkCity 101\n"
     ]
    }
   ],
   "source": [
    "with Pool(cpu_count()) as p:\n",
    "    for city in city_keys:\n",
    "        events = []\n",
    "        if (len(t_curr) == 0 or len(w_curr) == 0):\n",
    "            continue\n",
    "\n",
    "        file = f'../data/input/{city}_{years[0]}{months[0]}01_{years[-1]}{months[-1]}01.csv'\n",
    "        if os.path.exists(file):\n",
    "            os.remove(file)\n",
    "        per_cpu = len(tt_events[city])//cpu_count()\n",
    "        count = math.ceil(len(tt_events[city])/per_cpu)\n",
    "        args = [[city, per_cpu*i, per_cpu*(i+1), file] for i in range(count)]\n",
    "        print(city, count)\n",
    "        p.map(sample_input, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-27T02:41:29.103332Z",
     "iopub.status.busy": "2025-04-27T02:41:29.103056Z",
     "iopub.status.idle": "2025-04-27T02:41:29.105893Z",
     "shell.execute_reply": "2025-04-27T02:41:29.105594Z"
    }
   },
   "outputs": [],
   "source": [
    "# ## helper terminal??\n",
    "# # !echo '--- reading traffic events...'\n",
    "# # !head -n 3 TrafficEvents_Aug16_Dec20_Publish.csv\n",
    "# # !echo '--- reading weather events...'\n",
    "# # !head -n 3 WeatherEvents_Aug16_Dec20_Publish.csv\n",
    "# # !echo '--- traffic event types'\n",
    "# # !tail -n +2 TrafficEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $2}' | sort | uniq\n",
    "# # !echo '--- weather event types'\n",
    "# # !tail -n +2 WeatherEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $2}' | sort | uniq\n",
    "# # !echo '--- weather event severity'\n",
    "# # !tail -n +2 WeatherEvents_Aug16_Dec20_Publish.csv | awk -F, '{print $3}' | sort | uniq\n",
    "# # !tail -n+2 ../data/traffic/TD_Austin*.csv | awk -F, '{print $9,$10}' | sort | uniq | wc -l\n",
    "# # !tail -n+2 ../data/traffic/TD_Austin*.csv | wc -l\n",
    "\n",
    "\n",
    "# ## helper account details??\n",
    "# rr = requests.get('https://api.oikolab.com/account',\n",
    "#                  headers={'api-key': api_key}\n",
    "#                  )\n",
    "\n",
    "# rr.text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
